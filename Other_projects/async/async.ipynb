{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be73b3da",
   "metadata": {},
   "source": [
    "# Asynchronous Programming in Python\n",
    "Synchronous programming happens sequentially. This means code lines are executed in order from top to bottom. \n",
    "\n",
    "Asynchronous means tasks that take time can be awaited. This means that tasks that wait a long time can be put aside, and we can move to simultaneously trigger other tasks, while we wait.\n",
    "\n",
    "This can help a lot with minimising the execution time of certain types of tasks like requests and parrallel tasks. However, this will not improve the preformance of tasks chains that are dependant on the output of previous tasks, as we would still have to wait for the output to arrive if we need it for the next step.\n",
    "\n",
    "It is not multi threading, it is just switching off the processing to another function while waiting for the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78bbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ae53b",
   "metadata": {},
   "source": [
    "There are a few parts to this process. Asynchronous functions are not normal functions. In python they are called co-routines. To create a co-routine we use the ```async``` keyword prior to our normal function definition.\n",
    "In order to run a async function (co-routine) we must create an **event loop**. An event loop tracks the execution of the parts of your programme, and transfers the processing to other parts of the code while you are waiting on specific outputs. To create an event loop we execute our asynchronous function using the ```asyncio.run()``` function.\n",
    "The event loop must be told which parts of the code must run sequentially, and which parts can run asynchronously. For this inside our ```async``` functions we use the keyword ```await```.\n",
    "This seems intuitive, however, we can not create single lines of code that will run asynchronously within a single coroutine. You have to create a coroutine with an await statement, and then build that into a secondary coroutine that runs the initial coroutine. Because of this, we should create as many async coroutines as necessary and then run them using a 'parent' async coroutine.\n",
    "\n",
    "Here we have to use nest_asyncio as Jupyter notebooks require it as these types of files keep the event loop 'live'. In normal circumstances we wouldn't need that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0450917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coroutine 2: Start\n",
      "Time taken to surpass coroutine 1: 0.0000 seconds\n",
      "Coroutine 2: End\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coroutine 1: Start\n",
      "Coroutine 1: End\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def coroutine1():\n",
    "    print(\"Coroutine 1: Start\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Coroutine 1: End\")\n",
    "\n",
    "async def coroutine2():\n",
    "    print(\"Coroutine 2: Start\")\n",
    "    start_time = time.perf_counter()\n",
    "    asyncio.create_task(coroutine1())\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Time taken to surpass coroutine 1: {end_time - start_time:.4f} seconds\")\n",
    "    print(\"Coroutine 2: End\")\n",
    "    \n",
    "\n",
    "asyncio.run(coroutine2())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a39c8",
   "metadata": {},
   "source": [
    "ðŸ Asyncio Cheat Sheet: Core Concepts\n",
    "1. async def (The Definition)\n",
    "Purpose: Defines a function as a coroutine.\n",
    "\n",
    "What it does: It tells Python, \"This isn't a normal function; it's a task that can pause and resume.\" Calling this function returns a coroutine object but does not execute the code inside immediately.\n",
    "\n",
    "2. await (The Yield)\n",
    "Purpose: Pauses the current coroutine and hands control back to the Event Loop.\n",
    "\n",
    "What it does: It signals, \"I am waiting for this specific operation to finish. Event Loop, go run other tasks in the meantime.\" > Note: await can only be used inside an async def function.\n",
    "\n",
    "3. asyncio.create_task() (The Backgrounder)\n",
    "Purpose: Schedules a coroutine to run immediately in the background.\n",
    "\n",
    "What it does: It wraps a coroutine into a \"Task\" and adds it to the loop's queue. This allows the code to move to the next line without waiting for the task to finish, enabling concurrency.\n",
    "\n",
    "4. asyncio.gather() (The Batcher)\n",
    "Purpose: Runs multiple coroutines concurrently and waits for all of them to finish.\n",
    "\n",
    "What it does: It is a high-level tool to manage multiple tasks. It returns a list of results once the slowest task completes.\n",
    "\n",
    "5. asyncio.run() (The Ignition)\n",
    "Purpose: The entry point that starts the engine.\n",
    "\n",
    "What it does: It creates the Event Loop, runs the passed \"main\" coroutine, and shuts down the loop once finished.\n",
    "\n",
    "In Jupyter: You often don't need asyncio.run() because Jupyter runs its own event loop. You can often just use await main_function()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086758c",
   "metadata": {},
   "source": [
    "So basically we create asynchronous \"functions\" with the keyword ```async```. We must use the ```await``` keyword to get the event loop to go to do other tasks at specific points. This in of itself is not really that useful within a single coroutine. If we think of what is going on during the coroutine, we tell the event loop to stop execution of the particular function, until that particular sentence of code is completed. This is how it normally works anyway even without async.\n",
    "Where this becomes important is when we can combine multiple ```await``` statements, which has the potential to start many separate tasks, while waiting for others to be completed. To do this we must create many 'child' coroutines, and have a 'parent' coroutine to run them. In the parent we create tasks to run each child coroutine. This would be fine, except that by creating tasks we are not letting the 'parent' coroutine know what tasks to await before finishing execution. For this reason we must ```await``` each task within the parent coroutine. This can be done in a single step by using the built in ```gather()``` function. Finally we must use the ```.run()``` function to create and trigger the event loop.\n",
    "How this looks in code:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b945c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: Start\n",
      "Child 1: Start\n",
      "Child 2: Start\n",
      "Child 3: Start\n",
      "Child 2: End\n",
      "Child 3: End\n",
      "Child 1: End\n",
      "Parent: End\n"
     ]
    }
   ],
   "source": [
    "async def child1():\n",
    "    print(\"Child 1: Start\")\n",
    "    await asyncio.sleep(3)\n",
    "    print(\"Child 1: End\")\n",
    "\n",
    "async def child2():\n",
    "    print(\"Child 2: Start\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Child 2: End\")   \n",
    "\n",
    "async def child3():\n",
    "    print(\"Child 3: Start\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Child 3: End\")\n",
    "\n",
    "async def parent():\n",
    "    print(\"Parent: Start\")\n",
    "    await asyncio.gather(\n",
    "        child1(),\n",
    "        child2(),\n",
    "        child3()\n",
    "    )\n",
    "    print(\"Parent: End\")\n",
    "\n",
    "asyncio.run(parent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2b523",
   "metadata": {},
   "source": [
    "As you can see from the output above, because child1 sleeps for 3 seconds, that gives time for the event loop to switch to child2, and then child3 which even though they also rest for a second each, they still finish execution before child1. \n",
    "\n",
    "Because we used the ```gather``` function, the parent function knows to await all of these coroutines, before closing execution on the overall parent function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76173fd6",
   "metadata": {},
   "source": [
    "Asynchronous programming is important where we want to improve performance for tasks that have a lot of waiting, like web requests or I/O precedures. We can transfer processing to another codeblock while we await the response, making it more efficient. \n",
    "\n",
    "Now this has become important in GenAI. API calls to LLMs can sometimes have long wait times. We can use async to transfer to other processing tasks while we wait for the LLM to return the result\n",
    "\n",
    "We will demonstrate this below - we will use the scenario where we have API calls to a sequence of models. The first example will be the models working sequentially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "655dd69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Summary:\n",
      " Here is a concise summary combining the key points of both descriptions:\n",
      "\n",
      "The Standard Model is the prevailing theoretical framework in quantum physics that describes the fundamental constituents of matter and three of the four fundamental forces. Synthesized from principles of quantum field theory and symmetry, it functions as a \"periodic table\" for physics, classifying elementary particles into two main groups: **fermions** (matter building blocks, subdivided into quarks and leptons) and **bosons** (force carriers, including photons, gluons, W/Z bosons, and the mass-imparting Higgs boson).\n",
      "\n",
      "While the model has been rigorously validated through experimentsâ€”most notably the 2012 discovery of the Higgs bosonâ€”it is considered an incomplete theory. Its major limitations include the exclusion of gravity (which is described by general relativity) and its inability to explain cosmic phenomena such as dark matter, dark energy, neutrino masses, and matter-antimatter asymmetry.\n",
      "\n",
      "Total Time Taken: 30.5698 seconds\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "messages1 = [{\"role\": \"user\", \"content\": \"Tell me about the standard model of quantum physics\"},{\"role\": \"system\", \"content\": \"You are a helpful assistant. Your task is to Write a basic summary of the topic, including the most important points\"}]\n",
    "\n",
    "def fetch_response(model, messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def main():\n",
    "    start_time = time.perf_counter()\n",
    "    response1 = fetch_response(\"openai/gpt-4o-mini\", messages1)\n",
    "    response2 = fetch_response(\"google/gemini-2.0-flash-001\", messages1)\n",
    "    output1 = response1.choices[0].message.content\n",
    "    output2 = response2.choices[0].message.content\n",
    "\n",
    "    responses = f\"Output 1: {output1}\\n\\nOutput 2: {output2}\"\n",
    "    messages2 = [{\"role\": \"user\", \"content\": responses}, {\"role\": \"system\", \"content\": \"You are a helpful assistant. Your task is to Compare the two summaries and provide a single, concise summary that combines the key points from both.\"}]\n",
    "    final_response = fetch_response(model=\"google/gemini-3-pro-preview\", messages=messages2)\n",
    "    end_time = time.perf_counter()\n",
    "    final_output = final_response.choices[0].message.content\n",
    "    print(\"Final Summary:\\n\", final_output)\n",
    "    print(f\"\\nTotal Time Taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf67a84",
   "metadata": {},
   "source": [
    "So we can see if we run the models sequentially we end up running for around 30 seconds.\n",
    "\n",
    "Now lets create exactly the same process yet run the first model call asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "messages1 = [{\"role\": \"user\", \"content\": \"Tell me about the standard model of quantum physics\"},{\"role\": \"system\", \"content\": \"You are a helpful assistant. Your task is to Write a basic summary of the topic, including the most important points\"}]\n",
    "\n",
    "async def fetch_response(model, messages):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response\n",
    "\n",
    "async def main():\n",
    "    start_time = time.perf_counter()\n",
    "    response1, response2 = await asyncio.gather(fetch_response(\"openai/gpt-4o-mini\", messages1), fetch_response(\"google/gemini-2.0-flash-001\", messages1)\n",
    "    output1 = response1.choices[0].message.content\n",
    "    output2 = response2.choices[0].message.content\n",
    "\n",
    "    responses = f\"Output 1: {output1}\\n\\nOutput 2: {output2}\"\n",
    "    messages2 = [{\"role\": \"user\", \"content\": responses}, {\"role\": \"system\", \"content\": \"You are a helpful assistant. Your task is to Compare the two summaries and provide a single, concise summary that combines the key points from both.\"}]\n",
    "    final_response = await fetch_response(model=\"google/gemini-3-pro-preview\", messages=messages2)\n",
    "    end_time = time.perf_counter()\n",
    "    final_output = final_response.choices[0].message.content\n",
    "    print(\"Final Summary:\\n\", final_output)\n",
    "    print(f\"\\nTotal Time Taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
